<!DOCTYPE html>
<html>
 
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>NeRFace | CVPR 2021</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <meta name="google-site-verification" content="vIrKe6Ecwa3TVjmMt0OaJpDGw_SJa5IxzTA86wU44QE" />
    <style>
        :root {
            --bg: #f6f7fb;
            --surface: #ffffff;
            --text: #111827;
            --muted: #5b6475;
            --accent: #2f80ed;
            --accent-2: #6c63ff;
        }
        body {
            font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
            background: radial-gradient(1200px 400px at 10% -10%, rgba(47, 128, 237, 0.12), transparent),
                        radial-gradient(1000px 300px at 90% -10%, rgba(108, 99, 255, 0.12), transparent),
                        var(--bg);
            color: var(--text);
        }
        a { color: var(--accent); }
        a:hover { color: #1a6bd9; text-decoration: none; }
        .hero {
            padding: 56px 32px 32px;
            border-radius: 20px;
            background: linear-gradient(135deg, rgba(47, 128, 237, 0.08), rgba(108, 99, 255, 0.08));
            border: 1px solid rgba(15, 23, 42, 0.08);
            box-shadow: 0 30px 80px rgba(15, 23, 42, 0.12);
        }
        .badge-pill { font-weight: 600; }
        .section-card {
            background: var(--surface);
            border: 1px solid rgba(15, 23, 42, 0.08);
            border-radius: 16px;
            padding: 28px;
            margin-top: 24px;
        }
        .author-line a { color: var(--text); font-weight: 600; }
        .author-line a:hover { color: var(--accent); }
        .btn-ghost {
            border: 1px solid rgba(17, 24, 39, 0.2);
            color: var(--text);
            background: rgba(17, 24, 39, 0.02);
        }
        .btn-ghost:hover { border-color: var(--accent); color: var(--accent); }
        .video-frame, .paper-preview {
            border-radius: 14px;
            border: 1px solid rgba(15, 23, 42, 0.1);
            box-shadow: 0 20px 50px rgba(15, 23, 42, 0.12);
        }
        .lead { color: var(--muted); }
        .meta-row { color: var(--muted); font-size: 0.95rem; }
        .footer-note { color: var(--muted); font-size: 0.95rem; }
        pre { color: #1f2937; }
        .container-narrow { max-width: 980px; }
        .dropdown-menu {
            border-radius: 14px;
            border: 1px solid rgba(15, 23, 42, 0.08);
            box-shadow: 0 16px 30px rgba(15, 23, 42, 0.12);
        }
        .dropdown-item:active {
            background-color: rgba(47, 128, 237, 0.12);
            color: var(--text);
        }
        .pill-button {
            border-radius: 999px;
            padding: 8px 16px;
            font-weight: 600;
        }
        @media (max-width: 768px) {
            .hero { padding: 40px 20px 24px; }
            .section-card { padding: 20px; }
        }
    </style>
</head>

<body>
    <div class="container container-narrow py-5" id="paper">
        <div class="d-flex justify-content-center mb-3">
            <div class="dropdown">
                <button class="btn btn-ghost pill-button dropdown-toggle" type="button" id="moreResearch" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More research
                </button>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="moreResearch">
                    <a class="dropdown-item" href="https://edit-yourself.github.io" target="_blank">EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos</a>
                    <a class="dropdown-item" href="https://omergral.github.io/Semantify/" target="_blank">Semantify: Simplifying the Control of 3D Morphable Models using CLIP</a>
                </div>
            </div>
        </div>
        <div class="hero text-center">
            <p class="mb-2">
                <span class="badge badge-pill badge-info">CVPR 2021</span>
                <span class="badge badge-pill badge-light text-dark ml-2">Oral</span>
            </p>
            <h1 class="font-weight-bold mb-3">NeRFace: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction</h1>
            <p class="lead mb-4">
                Dynamic neural radiance fields for faithful, controllable 4D facial avatars from monocular videos.
            </p>
            <p class="author-line mb-2">
                <a target="_blank" href="http://www.niessnerlab.org/members/guy_gafni/profile.html">Guy Gafni</a><sup>1</sup>
                <span class="mx-2">Â·</span>
                <a target="_blank" href="https://justusthies.github.io/">Justus Thies</a><sup>1</sup>
                <span class="mx-2">Â·</span>
                <a target="_blank" href="https://zollhoefer.com/">Michael Zollh&ouml;fer</a><sup>2</sup>
                <span class="mx-2">Â·</span>
                <a target="_blank" href="https://www.niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie&szlig;ner</a><sup>1</sup>
            </p>
            <p class="meta-row mb-4">
                <sup>1</sup>Technical University of Munich
                <span class="mx-2">|</span>
                <sup>2</sup>Facebook Reality Labs
            </p>
            <div class="d-flex flex-wrap justify-content-center">
                <a class="btn btn-primary mx-2 mb-2" href="https://arxiv.org/pdf/2012.03065" target="_blank">ðŸ“„ PDF</a>
                <a class="btn btn-ghost mx-2 mb-2" href="https://arxiv.org/abs/2012.03065" target="_blank">ðŸ§¾ ArXiv</a>
                <a class="btn btn-ghost mx-2 mb-2" href="https://github.com/gafniguy/4D-Facial-Avatars" target="_blank">ðŸ’¾ Code &amp; Data</a>
                <a class="btn btn-ghost mx-2 mb-2" href="#video">ðŸŽ¬ Videos</a>
            </div>
        </div>

        <div class="section-card" id="tldr">
            <h3 class="mb-3">TL;DR</h3>
            <p class="lead mb-0">
                Condition NeRF on 3DMM parameters.
            </p>
        </div>

        <div class="section-card" id="introduction">
            <h3 class="mb-3">Introduction</h3>
            <p class="lead">
                We present dynamic neural radiance fields for modeling the appearance and dynamics of a human face.
            </p>
            <p>
                Digitally modeling and reconstructing a talking human is a key building-block for a variety of applications.
                Especially, for telepresence applications in AR or VR, a faithful reproduction of the appearance including novel viewpoint or head-poses is required.
                In contrast to state-of-the-art approaches that model the geometry and material properties explicitly, or are purely image-based, we introduce an implicit representation of the head based on scene representation networks.
                To handle the dynamics of the face, we combine our scene representation network with a low-dimensional morphable model which provides explicit control over pose and expressions.
                We use volumetric rendering to generate images from this hybrid representation and demonstrate that such a dynamic neural scene representation can be learned from monocular input data only, without the need of a specialized capture setup.
                In our experiments, we show that this learned volumetric representation allows for photo-realistic image generation that surpasses the quality of state-of-the-art video-based reenactment methods.
            </p>
        </div>

        <div class="section-card" id="video">
            <h3 class="mb-3">Videos</h3>
            <div class="mb-4">
                <video class="w-100 video-frame" controls playsinline preload="metadata">
                    <source src="vid.mp4" type="video/mp4">
                </video>
            </div>
            <div>
                <video class="w-100 video-frame" controls playsinline preload="metadata">
                    <source src="supp2.mp4" type="video/mp4">
                </video>
            </div>
        </div>

        <div class="section-card" id="publication">
            <h3 class="mb-3">Publication</h3>
            <p class="lead">
                Paper â€“ <a href="https://arxiv.org/pdf/2012.03065" target="_blank">PDF</a>
                (<a href="https://arxiv.org/abs/2012.03065" target="_blank">abs</a>)
                Â· <a href="https://github.com/gafniguy/4D-Facial-Avatars" target="_blank">GitHub</a>
            </p>
            <div class="text-center my-4">
                <a href="https://arxiv.org/pdf/2012.03065" target="_blank">
                    <img class="paper-preview img-fluid" src="paper_preview.PNG" alt="Paper preview">
                </a>
            </div>
            <p>If you find our work useful, please consider citing it:</p>
            <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">
@InProceedings{Gafni_2021_CVPR,
    author    = {Gafni, Guy and Thies, Justus and Zollh{\"o}fer, Michael and Nie{\ss}ner, Matthias},
    title     = {Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {8649-8658}
}
            </pre>
        </div>

        <div class="section-card" id="dataset">
            <h3 class="mb-3">Dataset</h3>
            <p class="footer-note mb-0">
                Please find our dataset through the GitHub repo. For any other questions contact us directly by email: guy.gafni at tum.de
            </p>
        </div>
    </div>
</body>
</html>
